import pandas as pd
import glob
import os
import re

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
downloads_dir = r"C:\Users\progr\Desktop\Python\mercari_dorekai\downloads"
brand_master_csv = r"C:\Users\progr\Desktop\Python\mercari_dorekai\brand_master_sjis.csv"
output_csv = r"C:\Users\progr\Desktop\Python\mercari_dorekai\ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡º.csv"
output_analysis_csv = r"C:\Users\progr\Desktop\Python\mercari_dorekai\ãƒ–ãƒ©ãƒ³ãƒ‰åˆ†æ.csv"

try:
    # æœ€æ–°ã®product_data_*.csvã‚’å–å¾—
    print("ğŸ“‚ æœ€æ–°ã®product_data_*.csvã‚’æ¤œç´¢ä¸­...")
    product_data_files = glob.glob(os.path.join(downloads_dir, "product_data_*.csv"))
    
    if not product_data_files:
        print("âŒ product_data_*.csvãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        exit()
    
    # æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆæ›´æ–°æ—¥æ™‚é †ï¼‰
    latest_file = max(product_data_files, key=os.path.getmtime)
    print(f"âœ… æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«: {os.path.basename(latest_file)}")
    
    # product_data_*.csvã‚’èª­ã¿è¾¼ã‚€
    print("ğŸ“‚ product_data_*.csvã‚’èª­ã¿è¾¼ã¿ä¸­...")
    for encoding in ['utf-8', 'shift_jis', 'cp932']:
        try:
            df_product = pd.read_csv(latest_file, encoding=encoding)
            print(f"âœ… èª­ã¿è¾¼ã¿æˆåŠŸ: {encoding}")
            break
        except Exception:
            continue
    else:
        print("âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—")
        exit()
    
    print(f"ğŸ“Š product_data: {len(df_product)} è¡Œ")
    print(f"ğŸ“‹ å…¨åˆ—: {list(df_product.columns)}")
    
    # ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡ºåˆ—ã‚’è¿½åŠ ï¼šå•†å“åã‹ã‚‰å‰åŠã®æ•°å­—ã¨ã‚¹ãƒšãƒ¼ã‚¹ã‚’å‰Šé™¤
    if 'å•†å“å' in df_product.columns:
        print(f"\nğŸ¯ ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡ºåˆ—ã‚’ä½œæˆä¸­...")
        
        def extract_brand_name(text):
            """ãƒ–ãƒ©ãƒ³ãƒ‰åã‚’æŠ½å‡ºã™ã‚‹
            1. å…ˆé ­ã®æ•°å­—ã¨ã‚¹ãƒšãƒ¼ã‚¹ã‚’å‰Šé™¤
            2. è‹±æ–‡ã®å¾Œã®æœ€åˆã®æ—¥æœ¬èªã®å¾Œã®æœ€åˆã®ã‚¹ãƒšãƒ¼ã‚¹å‰ã¾ã§
            """
            if pd.isna(text):
                return text
            
            text = str(text)
            
            # 1. å…ˆé ­ã®æ•°å­—ã¨ã‚¹ãƒšãƒ¼ã‚¹ã‚’å‰Šé™¤
            text = re.sub(r'^\d+\s+', '', text)
            
            # 2. è‹±æ–‡éƒ¨åˆ† + æ—¥æœ¬èªéƒ¨åˆ†ï¼ˆæœ€åˆã®ã‚¹ãƒšãƒ¼ã‚¹ã¾ã§ï¼‰ã‚’æŠ½å‡º
            # æ­£è¦è¡¨ç¾ï¼šè‹±æ•°å­—è¨˜å·ã®å¾Œã«æ—¥æœ¬èªãŒæ¥ã¦ã€ãã®å¾Œã®ã‚¹ãƒšãƒ¼ã‚¹ï¼ˆå…¨è§’ãƒ»åŠè§’ï¼‰ã¾ã§
            match = re.match(r'^([A-Za-z0-9&.\-\s]+?)([ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾¯]+?)[\sã€€]', text)
            if match:
                # è‹±æ–‡ + æ—¥æœ¬èªéƒ¨åˆ†ã‚’å–å¾—
                result = (match.group(1) + match.group(2)).strip()
                return result
            
            # ãƒãƒƒãƒã—ãªã„å ´åˆã¯æœ€åˆã®ã‚¹ãƒšãƒ¼ã‚¹ï¼ˆå…¨è§’ãƒ»åŠè§’ï¼‰ã¾ã§
            for i, char in enumerate(text):
                if char in [' ', 'ã€€', '\t']:
                    return text[:i].strip()
            
            # ã‚¹ãƒšãƒ¼ã‚¹ãŒãªã„å ´åˆã¯å…¨ä½“ã‚’è¿”ã™
            return text.strip()
        
        df_product['ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡º'] = df_product['å•†å“å'].apply(extract_brand_name)
        print(f"âœ… ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡ºåˆ—ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
        print(f"\nğŸ“ æŠ½å‡ºä¾‹:")
        print(df_product[['å•†å“å', 'ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡º']].head(5).to_string())
    
    # å…ƒã®DataFrameã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆå…¨åˆ—ã‚’ä¿æŒï¼‰
    df_extraction = df_product.copy()
    print(f"\nâœ… å…¨åˆ—ã‚’ä¿æŒ: {len(df_extraction.columns)} åˆ—")
    
    # brand_master_sjis.csvã‚’èª­ã¿è¾¼ã‚€
    print("\nğŸ“‚ brand_master_sjis.csvã‚’èª­ã¿è¾¼ã¿ä¸­...")
    for encoding in ['shift_jis', 'cp932', 'utf-8']:
        try:
            df_master = pd.read_csv(brand_master_csv, encoding=encoding)
            print(f"âœ… brand_master_sjis.csvèª­ã¿è¾¼ã¿æˆåŠŸ: {encoding}")
            break
        except Exception:
            continue
    else:
        print("âŒ brand_master_sjis.csvèª­ã¿è¾¼ã¿å¤±æ•—")
        exit()
    
    print(f"ğŸ“Š brand_master: {len(df_master)} è¡Œ")
    print(f"ğŸ“‹ åˆ—: {list(df_master.columns)}")
    
    # brand_master_sjis.csvã®åˆ—åã‚’å–å¾—
    master_cols = df_master.columns.tolist()
    brand_id_col = master_cols[0]  # æœ€åˆã®åˆ—ãŒãƒ–ãƒ©ãƒ³ãƒ‰ID
    brand_name_col = master_cols[1]  # 2ç•ªç›®ã®åˆ—ãŒãƒ–ãƒ©ãƒ³ãƒ‰å
    brand_kana_col = master_cols[2]  # 3ç•ªç›®ã®åˆ—ãŒãƒ–ãƒ©ãƒ³ãƒ‰åï¼ˆã‚«ãƒŠï¼‰
    
    print(f"   ãƒã‚¹ã‚¿åˆ—: {brand_id_col}, {brand_name_col}, {brand_kana_col}")
    
    # ãƒ–ãƒ©ãƒ³ãƒ‰IDã§ãƒãƒ¼ã‚¸ï¼ˆleft joinï¼‰
    print(f"\nğŸ”— ãƒ–ãƒ©ãƒ³ãƒ‰IDã§çµåˆä¸­...")
    df_merged = df_extraction.merge(
        df_master[[brand_id_col, brand_name_col, brand_kana_col]],
        left_on='ãƒ–ãƒ©ãƒ³ãƒ‰ID',
        right_on=brand_id_col,
        how='left'
    )
    
    # åˆ—åã‚’æ•´ç†
    df_merged = df_merged.rename(columns={
        brand_name_col: 'ãƒ–ãƒ©ãƒ³ãƒ‰å',
        brand_kana_col: 'ãƒ–ãƒ©ãƒ³ãƒ‰åï¼ˆã‚«ãƒŠï¼‰'
    })
    
    # ä¸è¦ãªåˆ—ã‚’å‰Šé™¤ï¼ˆé‡è¤‡ã—ãŸãƒ–ãƒ©ãƒ³ãƒ‰IDåˆ—ï¼‰
    if brand_id_col != 'ãƒ–ãƒ©ãƒ³ãƒ‰ID' and brand_id_col in df_merged.columns:
        df_merged = df_merged.drop(columns=[brand_id_col])
    
    # å…ƒã®CSVã®åˆ—é †ã‚’ç¶­æŒã—ã¤ã¤ã€ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡ºãƒ»ãƒ–ãƒ©ãƒ³ãƒ‰åãƒ»ãƒ–ãƒ©ãƒ³ãƒ‰åï¼ˆã‚«ãƒŠï¼‰ã‚’æœ«å°¾ã«é…ç½®
    original_cols = [col for col in df_product.columns if col in df_merged.columns]
    new_cols = ['ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡º', 'ãƒ–ãƒ©ãƒ³ãƒ‰å', 'ãƒ–ãƒ©ãƒ³ãƒ‰åï¼ˆã‚«ãƒŠï¼‰']
    cols_order = original_cols + [col for col in new_cols if col in df_merged.columns and col not in original_cols]
    df_merged = df_merged[cols_order]
    
    # çµæœã‚’è¡¨ç¤º
    print(f"\nâœ… ãƒãƒ¼ã‚¸å®Œäº†: {len(df_merged)} è¡Œ")
    print(f"ğŸ“‹ æœ€çµ‚åˆ—: {list(df_merged.columns)}")
    print(f"\nğŸ“ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:")
    print(df_merged.head(10).to_string())
    
    # ãƒãƒƒãƒç‡ã‚’è¡¨ç¤º
    matched = df_merged['ãƒ–ãƒ©ãƒ³ãƒ‰å'].notna().sum()
    total = len(df_merged)
    print(f"\nğŸ“Š ãƒãƒƒãƒç‡: {matched}/{total} ({matched/total*100:.1f}%)")
    
    # ç©ºã®ãƒ–ãƒ©ãƒ³ãƒ‰IDãŒã‚ã‚‹è¡Œã‚’è¡¨ç¤º
    empty_brand = df_merged[df_merged['ãƒ–ãƒ©ãƒ³ãƒ‰ID'].isna() | (df_merged['ãƒ–ãƒ©ãƒ³ãƒ‰ID'] == '')]
    if len(empty_brand) > 0:
        print(f"\nâš ï¸ ãƒ–ãƒ©ãƒ³ãƒ‰IDãŒç©ºã®å•†å“: {len(empty_brand)} ä»¶")
    
    # 2ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    
    # 1. ãƒ¡ãƒ«ã‚«ãƒªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ï¼šå…ƒã®åˆ—æ§‹æˆã®ã¿ï¼ˆãƒ–ãƒ©ãƒ³ãƒ‰åãƒ»ã‚«ãƒŠã‚’æ›´æ–°ï¼‰
    df_upload = df_merged[df_product.columns].copy()
    # ãƒ–ãƒ©ãƒ³ãƒ‰åã¨ãƒ–ãƒ©ãƒ³ãƒ‰åï¼ˆã‚«ãƒŠï¼‰ãŒå…ƒã®CSVã«ã‚ã‚Œã°æ›´æ–°
    if 'ãƒ–ãƒ©ãƒ³ãƒ‰å' in df_product.columns and 'ãƒ–ãƒ©ãƒ³ãƒ‰å' in df_merged.columns:
        df_upload['ãƒ–ãƒ©ãƒ³ãƒ‰å'] = df_merged['ãƒ–ãƒ©ãƒ³ãƒ‰å']
    if 'ãƒ–ãƒ©ãƒ³ãƒ‰åï¼ˆã‚«ãƒŠï¼‰' in df_product.columns and 'ãƒ–ãƒ©ãƒ³ãƒ‰åï¼ˆã‚«ãƒŠï¼‰' in df_merged.columns:
        df_upload['ãƒ–ãƒ©ãƒ³ãƒ‰åï¼ˆã‚«ãƒŠï¼‰'] = df_merged['ãƒ–ãƒ©ãƒ³ãƒ‰åï¼ˆã‚«ãƒŠï¼‰']
    
    df_upload.to_csv(output_csv, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ãƒ¡ãƒ«ã‚«ãƒªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜: {output_csv}")
    print(f"   åˆ—æ•°: {len(df_upload.columns)} (å…ƒã®CSVã¨åŒã˜)")
    
    # 2. åˆ†æç”¨ï¼šãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡ºåˆ—ã‚’è¿½åŠ  + ã‚½ãƒ¼ãƒˆ
    df_analysis = df_merged.copy()
    
    # ãƒ–ãƒ©ãƒ³ãƒ‰IDã®æœ‰ç„¡ã§åˆ†ã‘ã‚‹
    if 'ãƒ–ãƒ©ãƒ³ãƒ‰ID' in df_analysis.columns:
        # ãƒ–ãƒ©ãƒ³ãƒ‰IDãŒã‚ã‚‹å•†å“
        df_with_brand = df_analysis[df_analysis['ãƒ–ãƒ©ãƒ³ãƒ‰ID'].notna() & (df_analysis['ãƒ–ãƒ©ãƒ³ãƒ‰ID'] != '')].copy()
        # ãƒ–ãƒ©ãƒ³ãƒ‰IDãŒãªã„å•†å“
        df_without_brand = df_analysis[df_analysis['ãƒ–ãƒ©ãƒ³ãƒ‰ID'].isna() | (df_analysis['ãƒ–ãƒ©ãƒ³ãƒ‰ID'] == '')].copy()
        
        # 1. ãƒ–ãƒ©ãƒ³ãƒ‰IDãŒã‚ã‚‹å•†å“ï¼šãƒ–ãƒ©ãƒ³ãƒ‰IDå‡ºç¾å›æ•°ï¼ˆé™é †ï¼‰ + ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡ºï¼ˆæ˜‡é †ï¼‰
        if len(df_with_brand) > 0:
            brand_counts = df_with_brand['ãƒ–ãƒ©ãƒ³ãƒ‰ID'].value_counts()
            df_with_brand['_temp_count'] = df_with_brand['ãƒ–ãƒ©ãƒ³ãƒ‰ID'].map(brand_counts)
            
            if 'ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡º' in df_with_brand.columns:
                df_with_brand['_temp_brand_lower'] = df_with_brand['ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡º'].str.lower()
                df_with_brand = df_with_brand.sort_values(['_temp_count', '_temp_brand_lower'], ascending=[False, True])
                df_with_brand = df_with_brand.drop(columns=['_temp_count', '_temp_brand_lower'])
            else:
                df_with_brand = df_with_brand.sort_values('_temp_count', ascending=False)
                df_with_brand = df_with_brand.drop(columns=['_temp_count'])
        
        # 2. ãƒ–ãƒ©ãƒ³ãƒ‰IDãŒãªã„å•†å“ï¼šãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡ºã®å‡ºç¾å›æ•°ï¼ˆé™é †ï¼‰
        if len(df_without_brand) > 0 and 'ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡º' in df_without_brand.columns:
            brand_extract_counts = df_without_brand['ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡º'].value_counts()
            df_without_brand['_temp_extract_count'] = df_without_brand['ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡º'].map(brand_extract_counts)
            df_without_brand['_temp_brand_lower'] = df_without_brand['ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡º'].str.lower()
            df_without_brand = df_without_brand.sort_values(['_temp_extract_count', '_temp_brand_lower'], ascending=[False, True])
            df_without_brand = df_without_brand.drop(columns=['_temp_extract_count', '_temp_brand_lower'])
        
        # çµåˆï¼šãƒ–ãƒ©ãƒ³ãƒ‰IDã‚ã‚Š + ãƒ–ãƒ©ãƒ³ãƒ‰IDãªã—
        df_analysis = pd.concat([df_with_brand, df_without_brand], ignore_index=True)
        
        print(f"\nğŸ“Š ã‚½ãƒ¼ãƒˆå®Œäº†:")
        print(f"   - ãƒ–ãƒ©ãƒ³ãƒ‰IDã‚ã‚Š: {len(df_with_brand)} ä»¶ï¼ˆãƒ–ãƒ©ãƒ³ãƒ‰IDå‡ºç¾å›æ•°â†’ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡ºé †ï¼‰")
        print(f"   - ãƒ–ãƒ©ãƒ³ãƒ‰IDãªã—: {len(df_without_brand)} ä»¶ï¼ˆãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡ºå‡ºç¾å›æ•°é †ï¼‰")
    
    df_analysis.to_csv(output_analysis_csv, index=False, encoding='utf-8-sig')
    print(f"\nâœ… åˆ†æç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜: {output_analysis_csv}")
    print(f"   åˆ—æ•°: {len(df_analysis.columns)} (ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡ºãƒ»ãƒ–ãƒ©ãƒ³ãƒ‰åãƒ»ã‚«ãƒŠå«ã‚€)")
    
except Exception as e:
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    import traceback
    traceback.print_exc()
