import os
import re
import time
import pandas as pd
from pathlib import Path
from dotenv import load_dotenv
from playwright.sync_api import sync_playwright, TimeoutError
from typing import Optional, Dict, List

# --- è¨­å®š ---
ENV_PATH = r"C:\Users\progr\Desktop\Python\mercari_dorekai\.env"
USER_DATA_DIR = r"C:\Users\progr\Desktop\Python\mercari_dorekai\mercari_user_data"
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€
DOWNLOAD_DIR = r"C:\Users\progr\Desktop\Python\mercari_dorekai\downloads"
# dorekai_sheet_YYYY-MM-DD.xlsx ã‚’ä½¿ç”¨
XLSX_PREFIX = "dorekai_sheet_"
TARGET_URL = "https://mercari-shops.com/seller/shops/qWxSdPm7yRZ56vy6jEx9mK/products?tab=draft"

# ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆãƒŸãƒªç§’ï¼‰
PAGE_TIMEOUT = 60000
WAIT_SHORT = 0.5
WAIT_MEDIUM = 1
WAIT_LONG = 2
WAIT_FORM = 3

# é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
SKIP_KEYWORDS = ["ãƒŸã‚·ãƒ³å¾…ã¡", "ãƒŸã‚·ãƒ³"]

# ã‚«ãƒ†ã‚´ãƒªãƒ¼éšå±¤
CATEGORY_PATH = [
    "ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³",
    "ãƒ¬ãƒ‡ã‚£ãƒ¼ã‚¹",
    "ã‚¹ãƒ¼ãƒ„ãƒ»ãƒ•ã‚©ãƒ¼ãƒãƒ«ãƒ»ãƒ‰ãƒ¬ã‚¹",
    "ãƒ‰ãƒ¬ã‚¹ãƒ»ãƒ–ãƒ©ã‚¤ãƒ€ãƒ«",
    "ãƒŠã‚¤ãƒˆãƒ‰ãƒ¬ã‚¹ãƒ»ã‚­ãƒ£ãƒãƒ‰ãƒ¬ã‚¹"
]

def log(msg: str) -> None:
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ­ã‚°å‡ºåŠ›"""
    print(f"[{time.strftime('%H:%M:%S')}] {msg}")

def truncate_product_name(name: str, max_length: int = 100) -> str:
    """å•†å“åã‚’æŒ‡å®šæ–‡å­—æ•°ã«åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆå…¨è§’åŠè§’ã©ã¡ã‚‰ã‚‚1æ–‡å­—ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆï¼‰
    
    Args:
        name: å•†å“å
        max_length: æœ€å¤§æ–‡å­—æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100ï¼‰
        
    Returns:
        åˆ‡ã‚Šè©°ã‚ã‚‰ã‚ŒãŸå•†å“å
    """
    if len(name) <= max_length:
        return name
    return name[:max_length]

def wait_for_toast_disappear(page, timeout: int = 10000) -> None:
    """ãƒˆãƒ¼ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒæ¶ˆãˆã‚‹ã¾ã§å¾…æ©Ÿ
    
    Args:
        page: Playwrightã®ãƒšãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        timeout: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰
    """
    try:
        # ãƒˆãƒ¼ã‚¹ãƒˆãŒè¡¨ç¤ºã•ã‚Œã‚‹ã¾ã§å°‘ã—å¾…ã¤
        time.sleep(0.3)
        # ãƒˆãƒ¼ã‚¹ãƒˆãŒæ¶ˆãˆã‚‹ã¾ã§å¾…æ©Ÿ
        toast = page.locator('div.Toastify__toast')
        if toast.count() > 0:
            toast.wait_for(state="hidden", timeout=timeout)
            time.sleep(0.2)  # è¿½åŠ ã®å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³
    except Exception:
        # ãƒˆãƒ¼ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ç„¡è¦–
        pass

def extract_hinban(product_name: str) -> str:
    """å•†å“åã‹ã‚‰å“ç•ªï¼ˆå‰æ–¹ã®æ•°å­—ï¼‰ã‚’æŠ½å‡º
    
    Args:
        product_name: å•†å“å
        
    Returns:
        æŠ½å‡ºã•ã‚ŒãŸå“ç•ªï¼ˆæ•°å­—ã®ã¿ï¼‰
    """
    hinban = ""
    for char in product_name:
        if char.isdigit():
            hinban += char
        else:
            if hinban:  # æ•°å­—ãŒè¦‹ã¤ã‹ã£ãŸã‚‰çµ‚äº†
                break
    return hinban if hinban else product_name.strip()

def extract_brand_english(brand_name: str) -> str:
    """ãƒ–ãƒ©ãƒ³ãƒ‰åã‹ã‚‰æ¤œç´¢ç”¨ã®ãƒ–ãƒ©ãƒ³ãƒ‰åã‚’æŠ½å‡º
    
    Args:
        brand_name: ãƒ–ãƒ©ãƒ³ãƒ‰å
        
    Returns:
        æŠ½å‡ºã•ã‚ŒãŸãƒ–ãƒ©ãƒ³ãƒ‰å
    """
    brand_name = brand_name.strip()
    
    # ã€ŒXXX by YYYã€å½¢å¼ã®å ´åˆã€YYYã‚’è¿”ã™
    if ' by ' in brand_name.lower():
        parts = re.split(r' by ', brand_name, flags=re.IGNORECASE)
        if len(parts) > 1:
            return parts[1].strip()
    
    # å…ˆé ­ã®è‹±æ•°å­—éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã‚’å«ã‚€æœ€åˆã®å˜èªç¾¤ï¼‰
    match = re.match(r'^([A-Za-z0-9\s]+?)(?:\s*[ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾ ]|$)', brand_name)
    if match:
        return match.group(1).strip()
    
    return brand_name.split()[0] if brand_name else ""

def get_latest_dorekai_sheet_path() -> Optional[str]:
    """downloads ã‹ã‚‰æœ€æ–°ã® dorekai_sheet_*.xlsx ã‚’å–å¾—"""
    try:
        files = []
        for name in os.listdir(DOWNLOAD_DIR):
            if not name.startswith(XLSX_PREFIX) or not name.endswith(".xlsx"):
                continue
            full_path = os.path.join(DOWNLOAD_DIR, name)
            files.append(full_path)
        if not files:
            return None
        files.sort(key=lambda p: os.path.getmtime(p), reverse=True)
        return files[0]
    except Exception:
        return None

def load_product_data() -> Optional[pd.DataFrame]:
    """xlsxãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
    
    Returns:
        å•†å“ãƒ‡ãƒ¼ã‚¿ã®DataFrameã€å¤±æ•—æ™‚ã¯None
    """
    try:
        xlsx_path = get_latest_dorekai_sheet_path()
        if not xlsx_path:
            log(f"âŒ dorekai_sheet_*.xlsx ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {DOWNLOAD_DIR}")
            return None
        log(f"ğŸ“Š å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™: {xlsx_path}")
        df = pd.read_excel(xlsx_path, sheet_name="è‡ªå‹•ç”Ÿæˆçµæœ")
        log(f"âœ… {len(df)} ä»¶ã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        return df
    except Exception as e:
        log(f"âŒ xlsxãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def get_draft_products(page) -> List[Dict[str, str]]:
    """ä¸‹æ›¸ãã‚¿ãƒ–ã®å•†å“ä¸€è¦§ã‚’å–å¾—
    
    Args:
        page: Playwrightã®ãƒšãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        
    Returns:
        å•†å“æƒ…å ±ã®ãƒªã‚¹ãƒˆ
    """
    try:
        log("ğŸ“‹ ä¸‹æ›¸ãã‚¿ãƒ–ã®å•†å“ã‚’å–å¾—ä¸­...")
        
        # ä¸‹æ›¸ãã‚¿ãƒ–ã‚’ã‚¯ãƒªãƒƒã‚¯
        draft_tab = page.locator('button[data-testid="draft-tab"]')
        if draft_tab.count() > 0:
            draft_tab.click()
            time.sleep(WAIT_LONG)
        
        # å•†å“ãƒªã‚¹ãƒˆã‚’å–å¾—
        products = []
        product_items = page.locator('li[data-testid="product"]')
        count = product_items.count()
        
        log(f"ğŸ“¦ ä¸‹æ›¸ãå•†å“æ•°: {count}")
        
        for i in range(count):
            item = product_items.nth(i)
            product_name = item.locator('p[data-testid="product-name"]').inner_text().strip()
            products.append({
                "index": i,
                "product_name": product_name
            })
            log(f"   {i+1}. {product_name}")
        
        return products
    except Exception as e:
        log(f"âŒ ä¸‹æ›¸ãå•†å“å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def select_category(page) -> bool:
    """ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’è‡ªå‹•é¸æŠ
    
    Args:
        page: Playwrightã®ãƒšãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        
    Returns:
        æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
    """
    try:
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠãƒœã‚¿ãƒ³ã®çŠ¶æ…‹ã‚’ç¢ºèª
        category_button = page.locator('div[data-testid="categories"]')
        category_text = category_button.inner_text()
        
        # æ—¢ã«é¸æŠã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€å¾Œã®ã‚«ãƒ†ã‚´ãƒªåãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ã‹ï¼‰
        if CATEGORY_PATH[-1] in category_text:
            log(f"   âœ… ã‚«ãƒ†ã‚´ãƒªãƒ¼: {' > '.join(CATEGORY_PATH)} (æ—¢ã«é¸æŠæ¸ˆã¿)")
            return True
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠãŒå¿…è¦
        log(f"   ğŸ“‚ ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸æŠä¸­...")
        category_button.click()
        time.sleep(WAIT_MEDIUM)
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼éšå±¤ã‚’é †ç•ªã«é¸æŠ
        for i, category_name in enumerate(CATEGORY_PATH):
            # è©²å½“ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’æ¢ã—ã¦é¸æŠ
            option = page.locator(f'text="{category_name}"').first
            
            # è¦ç´ ãŒè¦‹ã¤ã‹ã‚‹ã¾ã§å°‘ã—å¾…ã¤
            try:
                option.wait_for(state="visible", timeout=5000)
            except:
                log(f"   âš ï¸ ã‚«ãƒ†ã‚´ãƒªãƒ¼ '{category_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
            
            option.click()
            time.sleep(WAIT_SHORT)
            
            # æœ€å¾Œã®ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠå¾Œã¯é•·ã‚ã«å¾…ã¤
            if i == len(CATEGORY_PATH) - 1:
                wait_for_toast_disappear(page)
                time.sleep(WAIT_MEDIUM)  # ã‚µã‚¤ã‚ºãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ãŒæœ‰åŠ¹ã«ãªã‚‹ã¾ã§å¾…ã¤
        
        log(f"   âœ… ã‚«ãƒ†ã‚´ãƒªãƒ¼: {' > '.join(CATEGORY_PATH)}")
        return True
    except Exception as e:
        log(f"   âš ï¸ ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠã‚¨ãƒ©ãƒ¼: {e}")
        return False

def select_size(page, product_data: Dict) -> bool:
    """ã‚µã‚¤ã‚ºã‚’è‡ªå‹•é¸æŠ
    
    Args:
        page: Playwrightã®ãƒšãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        product_data: å•†å“ãƒ‡ãƒ¼ã‚¿
        
    Returns:
        æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
    """
    if 'ã‚µã‚¤ã‚º' not in product_data or pd.isna(product_data['ã‚µã‚¤ã‚º']):
        log(f"   âš ï¸ ã‚µã‚¤ã‚º: ãƒ‡ãƒ¼ã‚¿ãªã—")
        return False
    
    size_input = str(product_data['ã‚µã‚¤ã‚º']).strip().upper()
    
    # ã‚µã‚¤ã‚ºãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ä¸¡å¯¾å¿œï¼‰
    size_mapping = {
        'XXSä»¥ä¸‹': ['XXS'],
        'XS(SS)': ['XS', 'SS'],
        'S': ['S'],
        'M': ['M'],
        'L': ['L'],
        'XL(LL)': ['XL', 'LL', '2L'],
        '2XL(3L)': ['2XL', '3L'],
        '3XL(4L)': ['3XL', '4L', 'XXXL'],
        '4XL(5L)ä»¥ä¸Š': ['4XL', '5L', 'XXXXL'],
        'FREE SIZE': ['FREE', 'ãƒ•ãƒªãƒ¼', 'F']
    }
    
    try:
        size_select = page.locator('select[name="ã‚µã‚¤ã‚º"]')
        options = size_select.locator('option')

        # å…¥åŠ›ã‚µã‚¤ã‚ºã‹ã‚‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚«ãƒ†ã‚´ãƒªã‚’æ±ºå®š
        target_size = None
        for size_key, keywords in size_mapping.items():
            if any(size_input == kw.upper() for kw in keywords):
                target_size = size_key
                break

        if not target_size:
            log(f"   âš ï¸ ã‚µã‚¤ã‚º: '{size_input}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False

        # é¸æŠè‚¢ã‚’å®Œå…¨ä¸€è‡´ã§æ¢ã™ï¼ˆéƒ¨åˆ†ä¸€è‡´ã¯ç¦æ­¢ï¼‰
        for j in range(options.count()):
            option_value = options.nth(j).get_attribute('value')
            option_text = options.nth(j).inner_text().strip()
            if option_text == target_size:
                size_select.select_option(option_value)
                log(f"   âœ… ã‚µã‚¤ã‚º: {option_text}")
                wait_for_toast_disappear(page)
                return True

        log(f"   âš ï¸ ã‚µã‚¤ã‚º: '{target_size}' ãŒé¸æŠè‚¢ã«ã‚ã‚Šã¾ã›ã‚“")
        return False
    except Exception as e:
        log(f"   âš ï¸ ã‚µã‚¤ã‚ºé¸æŠã‚¨ãƒ©ãƒ¼: {e}")
        return False

def input_brand(page, product_data: Dict) -> bool:
    """ãƒ–ãƒ©ãƒ³ãƒ‰ã‚’å…¥åŠ›ï¼ˆæ‰‹å‹•é¸æŠã‚’å¾…æ©Ÿï¼‰
    
    Args:
        page: Playwrightã®ãƒšãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        product_data: å•†å“ãƒ‡ãƒ¼ã‚¿
        
    Returns:
        æˆåŠŸæ™‚Trueã€ã‚¹ã‚­ãƒƒãƒ—æ™‚False
    """
    if 'ãƒ–ãƒ©ãƒ³ãƒ‰å' not in product_data or pd.isna(product_data['ãƒ–ãƒ©ãƒ³ãƒ‰å']):
        log(f"   âš ï¸ ãƒ–ãƒ©ãƒ³ãƒ‰: ãƒ‡ãƒ¼ã‚¿ãªã—")
        return False
    
    brand_full = str(product_data['ãƒ–ãƒ©ãƒ³ãƒ‰å']).strip()
    
    # ãƒãƒ¼ãƒ–ãƒ©ãƒ³ãƒ‰ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    if brand_full.upper() in ["ãƒãƒ¼ãƒ–ãƒ©ãƒ³ãƒ‰", "NO BRAND"]:
        log(f"   âš ï¸ ãƒ–ãƒ©ãƒ³ãƒ‰: ãƒãƒ¼ãƒ–ãƒ©ãƒ³ãƒ‰ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
        return False
    
    # ç‰¹ä¾‹: ROBE de FLEURS ã¯å›ºå®šã§æ¤œç´¢
    if "robe de fleurs" in brand_full.lower():
        brand_search = "ROBE de FLEURS"
    else:
        # è‹±èªéƒ¨åˆ†ã®ã¿ã‚’æŠ½å‡º
        brand_search = extract_brand_english(brand_full)
    
    if not brand_search:
        log(f"   âš ï¸ ãƒ–ãƒ©ãƒ³ãƒ‰: æŠ½å‡ºå¤±æ•—")
        return False
    
    try:
        log("â¸ï¸  ãƒ–ãƒ©ãƒ³ãƒ‰ã‚’æ‰‹å‹•ã§é¸æŠã—ã¦ãã ã•ã„ï¼š")
        log(f"      å…¥åŠ›å€¤: {brand_search}")
        
        brand_input = page.locator('input[data-testid="auto-complete-input"]')
        brand_input.clear()
        brand_input.fill(brand_search)
        time.sleep(WAIT_MEDIUM)
        
        log(f"   â¸ï¸  ãƒ–ãƒ©ãƒ³ãƒ‰æ¤œç´¢æ¬„ã«å…¥åŠ›ã•ã‚Œã¾ã—ãŸã€‚å€™è£œã‹ã‚‰é¸æŠã—ã¦ãã ã•ã„")
        log("   ğŸ’¡ å…¬é–‹ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨è‡ªå‹•çš„ã«æ¬¡ã®å•†å“ã«é€²ã¿ã¾ã™...")
        
        # å…¬é–‹å®Œäº†å¾Œã®ãƒšãƒ¼ã‚¸é·ç§»ã‚’å¾…æ©Ÿï¼ˆæœ€å¤§5åˆ†ï¼‰
        try:
            # URLãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¤‡æ•°è©¦ã™ï¼ˆopened ã‚¿ãƒ–ã¾ãŸã¯ draft ã‚¿ãƒ–ï¼‰
            page.wait_for_url(lambda url: "products" in url and ("tab=opened" in url or "tab=draft" in url), timeout=300000)
            log("   âœ… å…¬é–‹ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            return True
        except Exception as timeout_e:
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã§ã‚‚ã‚¹ã‚­ãƒƒãƒ—æ‰±ã„ã«ã—ã¦æ¬¡ã®å•†å“ã¸é€²ã‚ã‚‹
            log(f"   âš ï¸ ãƒ–ãƒ©ãƒ³ãƒ‰é¸æŠã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: æ‰‹å‹•ã§å…¬é–‹ã—ã¦ãã ã•ã„")
            log(f"   ğŸ’¡ æ¬¡ã®å•†å“ã¸é€²ã¿ã¾ã™...")
            return False
    except Exception as e:
        log(f"   âš ï¸ ãƒ–ãƒ©ãƒ³ãƒ‰å…¥åŠ›ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def fill_product_form(page, product_data: Dict) -> bool:
    """å•†å“æƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒ ã«å…¥åŠ›
    
    Args:
        page: Playwrightã®ãƒšãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        product_data: å•†å“ãƒ‡ãƒ¼ã‚¿
        
    Returns:
        æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
    """
    try:
        log(f"\nğŸ“ å•†å“æƒ…å ±ã‚’å…¥åŠ›ä¸­: {product_data.get('å“ç•ª', 'N/A')}")
        
        # å•†å“åï¼ˆãƒ¡ãƒ«ã‚«ãƒªã‚¿ã‚¤ãƒˆãƒ«ï¼‰
        if 'ãƒ¡ãƒ«ã‚«ãƒªã‚¿ã‚¤ãƒˆãƒ«' in product_data and pd.notna(product_data['ãƒ¡ãƒ«ã‚«ãƒªã‚¿ã‚¤ãƒˆãƒ«']):
            # å•†å“åã‚’100æ–‡å­—ã«åˆ¶é™
            original_name = str(product_data['ãƒ¡ãƒ«ã‚«ãƒªã‚¿ã‚¤ãƒˆãƒ«'])
            truncated_name = truncate_product_name(original_name, max_length=100)
            
            name_input = page.locator('input[name="name"]')
            name_input.clear()
            name_input.fill(truncated_name)
            
            if len(original_name) > 100:
                log(f"   âœ… å•†å“å: {truncated_name} (å…ƒ: {len(original_name)}æ–‡å­— â†’ 100æ–‡å­—ã«åˆ‡è©°)")
            else:
                log(f"   âœ… å•†å“å: {truncated_name}")
            
            wait_for_toast_disappear(page)
        else:
            log(f"   âš ï¸ å•†å“å: ãƒ‡ãƒ¼ã‚¿ãªã—")
        
        # å•†å“ã®èª¬æ˜ï¼ˆãƒ¡ãƒ«ã‚«ãƒªèª¬æ˜æ–‡ï¼‰
        if 'ãƒ¡ãƒ«ã‚«ãƒªèª¬æ˜æ–‡' in product_data and pd.notna(product_data['ãƒ¡ãƒ«ã‚«ãƒªèª¬æ˜æ–‡']):
            # ï¼Šç´ æ ç”Ÿåœ° è³ªæ„Ÿã‚’ä¿®æ­£
            description = str(product_data['ãƒ¡ãƒ«ã‚«ãƒªèª¬æ˜æ–‡'])
            description = re.sub(
                r'ï¼Šç´ æ ç”Ÿåœ° è³ªæ„Ÿ\s*\n([^\n]+)\n([^\n]+)',
                r'ï¼Šç´ æ ç”Ÿåœ° è³ªæ„Ÿ\n\1\nç”Ÿåœ°ã€è³ªæ„Ÿ\n\2',
                description
            )
            
            desc_textarea = page.locator('textarea[name="description"]')
            desc_textarea.clear()
            desc_textarea.fill(description)
            log(f"   âœ… å•†å“ã®èª¬æ˜: {len(description)} æ–‡å­—")
            wait_for_toast_disappear(page, timeout=3000)
        else:
            log(f"   âš ï¸ å•†å“ã®èª¬æ˜: ãƒ‡ãƒ¼ã‚¿ãªã—")
        
        # å•†å“ã®çŠ¶æ…‹ï¼ˆã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³1,2,3ã«åŸºã¥ã„ã¦åˆ¤å®šï¼‰
        condition_map = {
            'ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³3': ("CONDITION_BAD", "å…¨ä½“çš„ã«çŠ¶æ…‹ãŒæ‚ªã„"),
            'ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³2': ("CONDITION_DIRTY", "å‚·ã‚„æ±šã‚Œã‚ã‚Š"),
            'ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³1': ("CONDITION_LITTLE_DIRTY", "ã‚„ã‚„å‚·ã‚„æ±šã‚Œã‚ã‚Š"),
        }
        
        condition_value = "CONDITION_CLEAN"
        condition_label = "ç›®ç«‹ã£ãŸå‚·ã‚„æ±šã‚Œãªã— (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)"
        
        for cond_key, (cond_val, cond_lbl) in condition_map.items():
            if cond_key in product_data and pd.notna(product_data[cond_key]):
                condition_value = cond_val
                condition_label = f"{cond_lbl} ({cond_key})"
                break
        
        condition_select = page.locator('select[name="condition.id"]')
        condition_select.select_option(condition_value)
        log(f"   âœ… å•†å“ã®çŠ¶æ…‹: {condition_label}")
        wait_for_toast_disappear(page)
        
        # ã‚¯ãƒ¼ãƒ«åŒºåˆ†ã¯å¸¸ã«ã€Œé€šå¸¸ã€ã‚’é¸æŠ
        cool_select = page.locator('select[name="mercaribinForBusinessCoolType"]')
        cool_select.select_option("MERCARIBIN_FOR_BUSINESS_COOL_TYPE_NORMAL")
        log(f"   âœ… ã‚¯ãƒ¼ãƒ«åŒºåˆ†: é€šå¸¸")
        wait_for_toast_disappear(page)
        
        # è²©å£²ä¾¡æ ¼ï¼ˆè²©å£²å˜ä¾¡ï¼‰
        if 'è²©å£²å˜ä¾¡' in product_data and pd.notna(product_data['è²©å£²å˜ä¾¡']):
            try:
                price = int(float(product_data['è²©å£²å˜ä¾¡']))
                price_input = page.locator('input[name="price"]')
                price_input.clear()
                price_input.fill(str(price))
                log(f"   âœ… è²©å£²ä¾¡æ ¼: Â¥{price:,}")
                wait_for_toast_disappear(page, timeout=3000)
            except (ValueError, TypeError) as e:
                log(f"   âš ï¸ è²©å£²ä¾¡æ ¼: æ•°å€¤å¤‰æ›å¤±æ•— ({product_data['è²©å£²å˜ä¾¡']})")
        else:
            log(f"   âš ï¸ è²©å£²ä¾¡æ ¼: ãƒ‡ãƒ¼ã‚¿ãªã—")
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼è‡ªå‹•é¸æŠ
        select_category(page)
        
        # ã‚µã‚¤ã‚ºé¸æŠï¼ˆã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠå¾Œã«è¡¨ç¤ºã•ã‚Œã‚‹ï¼‰
        size_selected = select_size(page, product_data)
        
        log("âœ… è‡ªå‹•å…¥åŠ›å®Œäº†\n")
        
        # ãƒ–ãƒ©ãƒ³ãƒ‰ã¨ã‚µã‚¤ã‚ºãŒä¸¡æ–¹ãªã„å ´åˆã¯æ‰‹å‹•å…¥åŠ›ã‚’å¾…æ©Ÿ
        has_brand = 'ãƒ–ãƒ©ãƒ³ãƒ‰å' in product_data and pd.notna(product_data['ãƒ–ãƒ©ãƒ³ãƒ‰å']) and product_data['ãƒ–ãƒ©ãƒ³ãƒ‰å'].upper() not in ["ãƒãƒ¼ãƒ–ãƒ©ãƒ³ãƒ‰", "NO BRAND"]
        
        if not has_brand and not size_selected:
            log("âš ï¸ âš ï¸ âš ï¸ ãƒ–ãƒ©ãƒ³ãƒ‰ãƒ»ã‚µã‚¤ã‚ºä¸¡æ–¹ãŒã‚ã‚Šã¾ã›ã‚“ âš ï¸ âš ï¸ âš ï¸")
            log("ğŸ”’ ä»¥ä¸‹ã‚’æ‰‹å‹•ã§è¨­å®šã—ã¦ãã ã•ã„ï¼š")
            log("   1. ãƒ–ãƒ©ãƒ³ãƒ‰ã‚’é¸æŠ")
            log("   2. ã‚µã‚¤ã‚ºã‚’é¸æŠ")
            log("   3. å…¬é–‹ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯")
            log("=" * 70)
            
            # ãƒ–ãƒ©ãƒ³ãƒ‰ã‚’å…¥åŠ›ã—ã¦ã‹ã‚‰å…¬é–‹ã‚’å¾…æ©Ÿ
            input_brand(page, product_data)
        else:
            # ãƒ–ãƒ©ãƒ³ãƒ‰ï¼ˆè‹±èªéƒ¨åˆ†ã®ã¿å…¥åŠ›ã—ã¦ã‚¹ãƒˆãƒƒãƒ—ã€ãƒãƒ¼ãƒ–ãƒ©ãƒ³ãƒ‰ã¯ç„¡è¦–ï¼‰
            input_brand(page, product_data)
        
        return True
        
    except Exception as e:
        log(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ å…¥åŠ›ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def find_and_click_product(page, hinban: str) -> bool:
    """å“ç•ªã«ä¸€è‡´ã™ã‚‹å•†å“ã‚’æ¤œç´¢ã—ã¦ã‚¯ãƒªãƒƒã‚¯
    
    Args:
        page: Playwrightã®ãƒšãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        hinban: æ¤œç´¢ã™ã‚‹å“ç•ª
        
    Returns:
        æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
    """
    try:
        product_items = page.locator('li[data-testid="product"]')
        
        for i in range(product_items.count()):
            item = product_items.nth(i)
            current_product_name = item.locator('p[data-testid="product-name"]').inner_text().strip()
            current_hinban = extract_hinban(current_product_name)
            
            if str(current_hinban) == str(hinban):
                log(f"   âœ… å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {current_product_name}")
                item.click()
                time.sleep(WAIT_FORM)
                return True
        
        log(f"âš ï¸ å•†å“ãŒç¾åœ¨ã®ä¸€è¦§ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    except Exception as e:
        log(f"âŒ å•†å“æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def should_skip_product(product_name: str) -> bool:
    """å•†å“ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã¹ãã‹åˆ¤å®š
    
    Args:
        product_name: å•†å“å
        
    Returns:
        ã‚¹ã‚­ãƒƒãƒ—ã™ã¹ãå ´åˆTrue
    """
    return any(keyword in product_name for keyword in SKIP_KEYWORDS)

def main() -> None:
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    load_dotenv(ENV_PATH)
    
    # xlsxãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
    df = load_product_data()
    if df is None:
        return
    
    log("\nğŸš€ ãƒ–ãƒ©ã‚¦ã‚¶ã‚’èµ·å‹•ã—ã¦ã„ã¾ã™...")
    
    with sync_playwright() as p:
        context = p.chromium.launch_persistent_context(
            user_data_dir=USER_DATA_DIR,
            headless=False,
            channel="chrome",
            args=["--disable-blink-features=AutomationControlled"]
        )
        
        page = context.pages[0]
        page.set_default_timeout(PAGE_TIMEOUT)
        
        log(f"ğŸ“„ ãƒšãƒ¼ã‚¸ã«ç§»å‹•ã—ã¾ã™: {TARGET_URL}")
        page.goto(TARGET_URL)
        time.sleep(WAIT_FORM)
        
        # ä¸‹æ›¸ãå•†å“ã‚’å–å¾—
        draft_products = get_draft_products(page)
        
        if not draft_products:
            log("âš ï¸ ä¸‹æ›¸ãå•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            context.close()
            return
        
        # å„å•†å“ã‚’å‡¦ç†
        processed_count = 0
        skipped_count = 0
        
        for idx, draft_product in enumerate(draft_products):
            product_name = draft_product['product_name']
            
            # ã‚¹ã‚­ãƒƒãƒ—åˆ¤å®š
            if should_skip_product(product_name):
                log(f"\nâ­ï¸  ã‚¹ã‚­ãƒƒãƒ—: {product_name}ï¼ˆãƒŸã‚·ãƒ³å‡¦ç†ä¸­ã®ãŸã‚ç·¨é›†ç¦æ­¢ï¼‰")
                skipped_count += 1
                continue
            
            # å“ç•ªã‚’æŠ½å‡º
            hinban = extract_hinban(product_name)
            log(f"\nğŸ” å“ç•ªæŠ½å‡º: '{product_name}' â†’ '{hinban}'")
            
            # xlsxã‹ã‚‰è©²å½“ã™ã‚‹å“ç•ªã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
            matching_row = df[df['å“ç•ª'].astype(str) == str(hinban)]
            
            if matching_row.empty:
                log(f"âš ï¸ å“ç•ª {hinban} ã®ãƒ‡ãƒ¼ã‚¿ãŒxlsxã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                skipped_count += 1
                continue
            
            product_data = matching_row.iloc[0].to_dict()
            
            # å•†å“ã‚’æ¤œç´¢ã—ã¦ã‚¯ãƒªãƒƒã‚¯
            log(f"\nğŸ“¦ å•†å“ã‚’é–‹ã„ã¦ã„ã¾ã™: {hinban} ({idx+1}/{len(draft_products)})")
            
            if not find_and_click_product(page, hinban):
                skipped_count += 1
                continue
            
            # ãƒ•ã‚©ãƒ¼ãƒ ã«å…¥åŠ›
            if fill_product_form(page, product_data):
                processed_count += 1
            else:
                # å…¬é–‹ã•ã‚Œãšã«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ãŸå ´åˆã‚‚ã‚«ã‚¦ãƒ³ãƒˆ
                log(f"âš ï¸ å•†å“ {hinban} ã®å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™")
            
            # ä¸‹æ›¸ãä¸€è¦§ã«æˆ»ã‚‹ï¼ˆå…¬é–‹æ¸ˆã¿ãƒšãƒ¼ã‚¸ã‹ã‚‰æˆ»ã‚‹ï¼‰
            log(f"\nğŸ“‹ ä¸‹æ›¸ãä¸€è¦§ã«æˆ»ã‚Šã¾ã™...")
            page.goto(TARGET_URL)
            time.sleep(WAIT_LONG)
        
        log(f"\nâœ… ã™ã¹ã¦ã®å•†å“ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
        log(f"   å‡¦ç†æ¸ˆã¿: {processed_count} ä»¶")
        log(f"   ã‚¹ã‚­ãƒƒãƒ—: {skipped_count} ä»¶")
        log("ğŸ‘‹ ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã¾ã™")
        context.close()

if __name__ == "__main__":
    main()
