"""
ãƒ©ã‚¯ãƒã®å•†å“ã‚’å‰Šé™¤ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
products_rakuma.csv ã‹ã‚‰å‰Šé™¤å¯¾è±¡ãƒ»é‡è¤‡å¯¾è±¡ã®å•†å“ã‚’èª­ã¿è¾¼ã¿ã€å‰Šé™¤ã™ã‚‹
"""

import os
import pandas as pd
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError
import time

# --- è¨­å®š ---
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
RAKUMA_CSV = os.path.join(SCRIPT_DIR, 'products_rakuma.csv')
USER_DATA_DIR = os.path.join(SCRIPT_DIR, 'rakuma_user_data_firefox')
PROCESSED_URLS_FILE = os.path.join(SCRIPT_DIR, 'processed_rakuma_urls.txt')

def load_processed_rakuma_urls():
    """å‡¦ç†æ¸ˆã¿ãƒ©ã‚¯ãƒURLã®ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    if os.path.exists(PROCESSED_URLS_FILE):
        try:
            with open(PROCESSED_URLS_FILE, 'r', encoding='utf-8') as f:
                processed = set(line.strip() for line in f if line.strip())
            print(f"ğŸ“‹ å‡¦ç†æ¸ˆã¿URL {len(processed)} ä»¶ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
            return processed
        except Exception as e:
            print(f"âš ï¸ å‡¦ç†æ¸ˆã¿URLãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return set()
    return set()

def save_processed_rakuma_url(url):
    """å‡¦ç†æ¸ˆã¿URLã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜"""
    try:
        with open(PROCESSED_URLS_FILE, 'a', encoding='utf-8') as f:
            f.write(url + '\n')
    except Exception as e:
        print(f"âš ï¸ å‡¦ç†æ¸ˆã¿URLã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

def load_target_urls_from_csv():
    """products_rakuma.csv ã‹ã‚‰å‰Šé™¤å¯¾è±¡ãƒ»é‡è¤‡å¯¾è±¡ã®URLã‚’æŠ½å‡ºï¼ˆé‡è¤‡ã¯å¤ã„æ–¹ã‚’å‰Šé™¤ï¼‰"""
    if not os.path.exists(RAKUMA_CSV):
        print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {RAKUMA_CSV}")
        return []
    
    try:
        df = pd.read_csv(RAKUMA_CSV, encoding='utf-8-sig')
        
        # å‰Šé™¤å¯¾è±¡
        delete_targets = pd.DataFrame()
        if 'å‰Šé™¤' in df.columns:
            delete_targets = df[df['å‰Šé™¤'] == 'å‰Šé™¤'].copy()
        
        # é‡è¤‡å¯¾è±¡ï¼ˆå“ç•ªã”ã¨ã«æ–°ã—ã„1ä»¶ã‚’æ®‹ã—ã¦å¤ã„æ–¹ã‚’å‰Šé™¤ï¼‰
        duplicate_targets = pd.DataFrame()
        if 'é‡è¤‡' in df.columns and 'å“ç•ª' in df.columns:
            dup_df = df[df['é‡è¤‡'] == 'é‡è¤‡'].copy()
            if not dup_df.empty and 'URL' in dup_df.columns:
                date_col = None
                for col in ['æœ€çµ‚æ›´æ–°æ—¥æ™‚', 'å•†å“ç™»éŒ²æ—¥æ™‚']:
                    if col in dup_df.columns:
                        date_col = col
                        break

                dup_df = dup_df.dropna(subset=['URL']).copy()

                if date_col:
                    dup_df['_sort_dt'] = pd.to_datetime(dup_df[date_col], errors='coerce')
                    dup_df['_sort_dt'] = dup_df['_sort_dt'].fillna(pd.Timestamp.min)
                    dup_df = dup_df.sort_values(['å“ç•ª', '_sort_dt', 'URL'], ascending=[True, False, True])
                    dup_df['_dup_rank'] = dup_df.groupby('å“ç•ª').cumcount()
                else:
                    dup_df['_dup_rank'] = dup_df.groupby('å“ç•ª').cumcount()

                duplicate_targets = dup_df[dup_df['_dup_rank'] > 0].copy()
        
        # çµ±åˆ
        if 'URL' in df.columns:
            combined = pd.concat([delete_targets, duplicate_targets], ignore_index=True)
            combined = combined.dropna(subset=['URL']).drop_duplicates(subset=['URL'])
            urls = combined['URL'].tolist()
            
            print(f"ğŸ“¦ å‰Šé™¤å¯¾è±¡: {len(delete_targets)} ä»¶")
            print(f"ğŸ” é‡è¤‡å¯¾è±¡ï¼ˆå¤ã„æ–¹ï¼‰: {len(duplicate_targets)} ä»¶")
            print(f"âœ… åˆè¨ˆ: {len(urls)} ä»¶ã®URLã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
            
            return urls
        else:
            print("âŒ CSVã«'URL'åˆ—ãŒã‚ã‚Šã¾ã›ã‚“")
            return []
            
    except Exception as e:
        print(f"âŒ CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def convert_to_edit_url(url):
    """URLã‚’ç·¨é›†ãƒšãƒ¼ã‚¸å½¢å¼ã«å¤‰æ›"""
    if '/edit' in url:
        return url
    
    if 'item.fril.jp/' in url:
        # ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é™¤å»
        base_url = url.split('?')[0]
        # item.fril.jp/{id} ã‹ã‚‰ {id} ã‚’æŠ½å‡º
        parts = base_url.split('item.fril.jp/')
        if len(parts) > 1:
            item_id = parts[1].rstrip('/')
            # fril.jp/item/{id}/edit å½¢å¼ã«å¤‰æ›
            return f"https://fril.jp/item/{item_id}/edit"
    
    return url

def delete_products(product_urls):
    """ãƒ©ã‚¯ãƒã®å•†å“ã‚’å‰Šé™¤ã™ã‚‹"""
    if not product_urls:
        print("âœ… å‡¦ç†å¯¾è±¡ã®URLãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # URLã‚’ç·¨é›†ãƒšãƒ¼ã‚¸å½¢å¼ã«å¤‰æ›
    # https://item.fril.jp/{id} â†’ https://fril.jp/item/{id}/edit
    edit_urls = []
    for url in product_urls:
        edit_url = convert_to_edit_url(url)
        edit_urls.append(edit_url)
        if edit_url != url:
            print(f"ğŸ“ å¤‰æ›: {url}")
            print(f"    â†’ {edit_url}")
    
    with sync_playwright() as p:
        # Firefoxãƒ–ãƒ©ã‚¦ã‚¶ã‚’èµ·å‹•ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒï¼‰
        print("ğŸŒ ãƒ–ãƒ©ã‚¦ã‚¶ã‚’èµ·å‹•ä¸­...")
        browser = p.firefox.launch_persistent_context(
            user_data_dir=USER_DATA_DIR,
            headless=False,
            slow_mo=500
        )
        
        page = browser.pages[0] if browser.pages else browser.new_page()
        
        # æ‰‹å‹•ãƒ­ã‚°ã‚¤ãƒ³ã®æ©Ÿä¼šã‚’æä¾›
        print("\n" + "=" * 70)
        print("ğŸ” ãƒ­ã‚°ã‚¤ãƒ³ç¢ºèªã¨æ‰‹å‹•ãƒ­ã‚°ã‚¤ãƒ³ã®æ™‚é–“")
        print("=" * 70)
        print("ğŸ“Œ ãƒ–ãƒ©ã‚¦ã‚¶ã‚’èµ·å‹•ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ã‚’ç¢ºèªã—ã¾ã™")
        print("=" * 70)
        
        # ãƒã‚¤ãƒšãƒ¼ã‚¸ã«ç›´æ¥é·ç§»ï¼ˆãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ãªã‚‰ãã®ã¾ã¾è¡¨ç¤ºã€æœªãƒ­ã‚°ã‚¤ãƒ³ãªã‚‰ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã¸ï¼‰
        print("\nğŸŒ ãƒã‚¤ãƒšãƒ¼ã‚¸ã‚’é–‹ã„ã¦ã„ã¾ã™...")
        try:
            page.goto("https://fril.jp/mypage", timeout=30000)
            page.wait_for_timeout(3000)
            
            # ç¾åœ¨ã®URLã‚’ç¢ºèª
            current_url = page.url
            print(f"ğŸ“ ç¾åœ¨ã®URL: {current_url}")
            
            # ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã•ã‚ŒãŸå ´åˆ
            if "login" in current_url.lower():
                print("âš ï¸ ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™ã€‚")
                # Persistent Contextã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€é€šå¸¸ã¯è‡ªå‹•ãƒ­ã‚°ã‚¤ãƒ³ã•ã‚Œã‚‹ã¯ãš
                # æ•°ç§’å¾…ã£ã¦ã‹ã‚‰å†ç¢ºèª
                page.wait_for_timeout(5000)
                current_url = page.url
                if "login" in current_url.lower():
                    print("âŒ ãƒ­ã‚°ã‚¤ãƒ³ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã§ä¸€åº¦æ‰‹å‹•ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                    browser.close()
                    return
            
            print("âœ… ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ã§ã™")
        except Exception as e:
            print(f"âš ï¸ ãƒšãƒ¼ã‚¸é·ç§»ã‚¨ãƒ©ãƒ¼: {e}")
            print("å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™...")
        
        # ãƒ­ã‚°ã‚¤ãƒ³å¾Œã®ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆå®Œäº†ã‚’å¾…ã¤
        print("\nâ³ ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ã®å®Œäº†ã‚’å¾…ã£ã¦ã„ã¾ã™...")
        page.wait_for_timeout(5000)  # 5ç§’å¾…æ©Ÿã—ã¦ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆå®Œäº†ã‚’å¾…ã¤
        
        # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ãŒãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚„ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆä¸­ã§ãªã„ã‹ç¢ºèª
        current_url = page.url
        print(f"ğŸ“ ãƒ­ã‚°ã‚¤ãƒ³å¾Œã®URL: {current_url}")
        
        # ã‚‚ã—ã¾ã ãƒ­ã‚°ã‚¤ãƒ³é–¢é€£ã®URLãªã‚‰ã€ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆå®Œäº†ã‚’å¾…ã¤
        if "login" in current_url.lower() or "authorize" in current_url.lower() or "callback" in current_url.lower():
            print("ğŸ”„ ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆå‡¦ç†ä¸­ã§ã™ã€‚å®Œäº†ã‚’å¾…ã£ã¦ã„ã¾ã™...")
            try:
                # ãƒ­ã‚°ã‚¤ãƒ³é–¢é€£ã®URLã§ãªããªã‚‹ã¾ã§å¾…æ©Ÿï¼ˆæœ€å¤§30ç§’ï¼‰
                page.wait_for_url(
                    lambda url: "login" not in url.lower() and "authorize" not in url.lower() and "callback" not in url.lower(),
                    timeout=30000
                )
                print("âœ… ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆå®Œäº†")
                page.wait_for_timeout(2000)
            except:
                print("âš ï¸ ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€‚ãã®ã¾ã¾ç¶šè¡Œã—ã¾ã™")
        
        # ãƒ­ã‚°ã‚¤ãƒ³ç¢ºèª
        print("\nğŸ” ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ã‚’ç¢ºèªä¸­...")
        try:
            page.goto("https://fril.jp/mypage", timeout=60000, wait_until="domcontentloaded")
            page.wait_for_timeout(3000)
        except Exception as e:
            print(f"âš ï¸ ãƒã‚¤ãƒšãƒ¼ã‚¸ã¸ã®é·ç§»ã‚¨ãƒ©ãƒ¼: {e}")
            print("ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ã§ç¢ºèªã‚’ç¶šã‘ã¾ã™...")
        
        current_url = page.url
        print(f"ğŸ“ ç¢ºèªURL: {current_url}")
        
        if "login" in current_url.lower():
            print("âŒ ãƒ­ã‚°ã‚¤ãƒ³ãŒç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸ")
            print("âš ï¸ ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™ã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            
            # Slacké€šçŸ¥ã‚’é€ä¿¡ï¼ˆãƒ­ã‚°ã‚¤ãƒ³åˆ‡ã‚Œï¼‰
            try:
                import subprocess
                subprocess.run([
                    r"..\venv\Scripts\python.exe", 
                    "send_slack_notification.py",
                    "âŒ ãƒ©ã‚¯ãƒå‰Šé™¤: ãƒ­ã‚°ã‚¤ãƒ³ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆ‡ã‚Œã¦ã„ã¾ã™ã€‚æ‰‹å‹•ã§ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™ã€‚",
                    "error"
                ], cwd=os.path.dirname(os.path.abspath(__file__)))
            except:
                pass
            
            browser.close()
            return
        
        print("âœ… ãƒ­ã‚°ã‚¤ãƒ³å®Œäº†ã‚’ç¢ºèªã—ã¾ã—ãŸ")
        
        # Cookieã‚’ç¢ºèªã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’è¡¨ç¤º
        cookies = browser.cookies()
        fril_cookies = [c for c in cookies if 'fril.jp' in c.get('domain', '')]
        print(f"ğŸª ãƒ©ã‚¯ãƒã®Cookieæ•°: {len(fril_cookies)}")
        
        if fril_cookies:
            print("âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒç¢ºç«‹ã•ã‚Œã¾ã—ãŸ")
            # ä¸»è¦ãªCookieåã‚’è¡¨ç¤º
            cookie_names = [c.get('name', '') for c in fril_cookies]
            print(f"   Cookieå: {', '.join(cookie_names[:5])}")  # æœ€åˆã®5ã¤ã‚’è¡¨ç¤º
        else:
            print("âš ï¸ Cookie ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒä¸å®‰å®šãªå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        # å‡¦ç†é–‹å§‹
        print(f"\nğŸ—‘ï¸ {len(edit_urls)} ä»¶ã®å•†å“ã‚’å‰Šé™¤ã—ã¾ã™\n")
        
        success_count = 0
        fail_count = 0
        
        for idx, url in enumerate(edit_urls, 1):
            print(f"[{idx}/{len(edit_urls)}] {url}")
            
            try:
                # å•†å“ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
                try:
                    # ã¾ãšãƒã‚¤ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ç¢ºèªï¼ˆãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰
                    retry_count = 0
                    max_retries = 2
                    
                    while retry_count <= max_retries:
                        try:
                            page.goto("https://fril.jp/mypage", timeout=60000, wait_until="domcontentloaded")
                            page.wait_for_timeout(1000)
                            break
                        except Exception as retry_error:
                            retry_count += 1
                            if retry_count > max_retries:
                                raise retry_error
                            print(f"  ğŸ”„ ãƒªãƒˆãƒ©ã‚¤ {retry_count}/{max_retries}...")
                            page.wait_for_timeout(3000)
                    
                    if "login" in page.url.lower():
                        print("  âš ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆ‡ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®å•†å“ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        continue
                    
                    # å•†å“ç·¨é›†ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
                    page.goto(url, timeout=60000, wait_until="domcontentloaded")
                    page.wait_for_timeout(3000)
                    
                    # ãƒšãƒ¼ã‚¸é·ç§»å¾Œã®URLã‚’ç¢ºèªã—ã¦ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
                    current_url = page.url
                    print(f"  ğŸ“ ã‚¢ã‚¯ã‚»ã‚¹å…ˆ: {current_url}")
                    
                    # 404ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ã®ãƒã‚§ãƒƒã‚¯
                    if page.locator('h1.css-s6ybq1:has-text("ãŠæ¢ã—ã®ãƒšãƒ¼ã‚¸ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")').count() > 0:
                        print("  âš ï¸ ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆå‰Šé™¤æ¸ˆã¿ã¾ãŸã¯ç„¡åŠ¹ãªURLï¼‰")
                        print("  â†’ å‡¦ç†æ¸ˆã¿ã«è¨˜éŒ²ã—ã¦ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                        save_processed_rakuma_url(url)
                        success_count += 1
                        continue
                    
                    if "login" in current_url.lower():
                        print("  âŒ ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã•ã‚Œã¾ã—ãŸ")
                        print("  ğŸ”’ ãƒ–ãƒ©ã‚¦ã‚¶ã§ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„...")
                        # ãƒ­ã‚°ã‚¤ãƒ³å®Œäº†ã‚’å¾…ã¤ï¼ˆæœ€å¤§60ç§’ï¼‰
                        try:
                            page.wait_for_url(lambda u: "login" not in u.lower() and "edit" in u.lower(), timeout=60000)
                            print("  âœ… ãƒ­ã‚°ã‚¤ãƒ³å®Œäº†ã€å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™")
                            page.wait_for_timeout(2000)
                        except:
                            print("  âŒ ãƒ­ã‚°ã‚¤ãƒ³ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€ã“ã®å•†å“ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                            fail_count += 1
                            continue
                    
                except Exception as goto_error:
                    print(f"  âŒ ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: {goto_error}")
                    fail_count += 1
                    continue
                
                # ã€Œå‰Šé™¤ã™ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’æ¢ã™
                delete_button = None

                # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ãƒ†ã‚­ã‚¹ãƒˆã§æ¤œç´¢
                try:
                    delete_button = page.get_by_text("å‰Šé™¤ã™ã‚‹", exact=False).first
                    if delete_button and delete_button.is_visible(timeout=2000):
                        delete_button.click()
                        print("  ğŸ—‘ï¸ ã€Œå‰Šé™¤ã™ã‚‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯")
                    else:
                        delete_button = None
                except:
                    delete_button = None

                # ãƒ‘ã‚¿ãƒ¼ãƒ³2: CSSã‚»ãƒ¬ã‚¯ã‚¿ã§æ¤œç´¢
                if not delete_button:
                    try:
                        delete_button = page.locator('button:has-text("å‰Šé™¤ã™ã‚‹")').first
                        if delete_button.count() > 0:
                            delete_button.click(timeout=3000)
                            print("  ğŸ—‘ï¸ ã€Œå‰Šé™¤ã™ã‚‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯")
                        else:
                            delete_button = None
                    except:
                        delete_button = None

                # ãƒ‘ã‚¿ãƒ¼ãƒ³3: aã‚¿ã‚°ã§æ¤œç´¢
                if not delete_button:
                    try:
                        delete_button = page.locator('a:has-text("å‰Šé™¤ã™ã‚‹")').first
                        if delete_button.count() > 0:
                            delete_button.click(timeout=3000)
                            print("  ğŸ—‘ï¸ ã€Œå‰Šé™¤ã™ã‚‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯")
                        else:
                            delete_button = None
                    except:
                        delete_button = None

                if not delete_button:
                    print("  âš ï¸ å‰Šé™¤ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆæ—¢ã«å‰Šé™¤æ¸ˆã¿ or å£²å´æ¸ˆã¿ï¼‰")
                    fail_count += 1
                    continue

                # ãƒ¢ãƒ¼ãƒ€ãƒ«ã®ç¢ºèªãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
                page.wait_for_timeout(1000)
                
                try:
                    confirm_clicked = False
                    dialog = page.locator('div[role="dialog"]').last
                    if dialog.count() > 0:
                        confirm_button = dialog.locator('button:has-text("å‰Šé™¤")').first
                        if confirm_button.count() > 0:
                            confirm_button.click(timeout=5000)
                            confirm_clicked = True
                        else:
                            confirm_button = dialog.locator('button:has-text("ã¯ã„")').first
                            if confirm_button.count() > 0:
                                confirm_button.click(timeout=5000)
                                confirm_clicked = True

                    if not confirm_clicked:
                        confirm_button = page.locator('button:has-text("å‰Šé™¤")').first
                        if confirm_button.count() > 0 and confirm_button.is_visible(timeout=2000):
                            confirm_button.click(timeout=5000)
                            confirm_clicked = True

                    if not confirm_clicked:
                        print("  âŒ ç¢ºèªãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        fail_count += 1
                        continue

                    # ãƒšãƒ¼ã‚¸é·ç§»ã¾ãŸã¯é€šçŸ¥ã‚’å¾…ã¤ï¼ˆæœ€å¤§10ç§’ï¼‰
                    before_url = page.url
                    page.wait_for_timeout(3000)

                    # çµæœã‚’ç¢ºèª
                    after_url = page.url

                    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: URLå¤‰åŒ–ã§æˆåŠŸåˆ¤å®šï¼ˆç·¨é›†ãƒšãƒ¼ã‚¸ã‹ã‚‰é›¢è„±ï¼‰
                    if before_url != after_url and "/edit" not in after_url:
                        print("  âœ… å‰Šé™¤ã—ã¾ã—ãŸï¼ˆãƒšãƒ¼ã‚¸é·ç§»ï¼‰")
                        success_count += 1
                        save_processed_rakuma_url(url)
                    else:
                        # æˆåŠŸé€šçŸ¥ã‚’ç¢ºèª
                        try:
                            notice = page.locator('p#notice').first
                            if notice.count() > 0 and notice.is_visible():
                                notice_text = notice.text_content()
                                if "å‰Šé™¤" in notice_text:
                                    print(f"  âœ… å‰Šé™¤ã—ã¾ã—ãŸ: {notice_text}")
                                    success_count += 1
                                    save_processed_rakuma_url(url)
                                else:
                                    print(f"  âš ï¸ äºˆæœŸã—ãªã„é€šçŸ¥: {notice_text}")
                                    fail_count += 1
                            else:
                                # é€šçŸ¥ãŒè¡¨ç¤ºã•ã‚Œãªã„ = å£²å´æ¸ˆã¿ã¾ãŸã¯å‰Šé™¤æ¸ˆã¿
                                print("  âš ï¸ ã“ã®å•†å“ã¯æ—¢ã«å£²å´æ¸ˆã¿ã¾ãŸã¯å‰Šé™¤æ¸ˆã¿ã§ã™ï¼ˆå‡¦ç†æ¸ˆã¿ã«è¨˜éŒ²ï¼‰")
                                save_processed_rakuma_url(url)
                                success_count += 1
                        except Exception as e:
                            print(f"  âš ï¸ é€šçŸ¥ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
                            fail_count += 1
                        
                except PlaywrightTimeoutError:
                    print("  âŒ ç¢ºèªãƒœã‚¿ãƒ³ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
                    fail_count += 1
                    
            except Exception as e:
                print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                fail_count += 1
            
            # æ¬¡ã®å•†å“ã¾ã§ã®å¾…æ©Ÿ
            if idx < len(edit_urls):
                page.wait_for_timeout(2000)
        
        print(f"\nğŸ“Š å‡¦ç†å®Œäº†: æˆåŠŸ {success_count} ä»¶ / å¤±æ•— {fail_count} ä»¶")
        
        browser.close()

def main():
    print("=" * 60)
    print("ãƒ©ã‚¯ãƒå•†å“ å‰Šé™¤ãƒ„ãƒ¼ãƒ«")
    print("=" * 60)
    
    # å‡¦ç†æ¸ˆã¿URLã‚’èª­ã¿è¾¼ã¿
    processed_urls = load_processed_rakuma_urls()
    
    # CSVã‹ã‚‰å¯¾è±¡URLã‚’èª­ã¿è¾¼ã¿
    target_urls = load_target_urls_from_csv()
    
    if not target_urls:
        print("âœ… å‡¦ç†å¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # URLã‚’ç·¨é›†ãƒšãƒ¼ã‚¸å½¢å¼ã«å¤‰æ›ã—ã¦ã‹ã‚‰æ¯”è¼ƒ
    target_edit_urls = [convert_to_edit_url(url) for url in target_urls]
    
    # æœªå‡¦ç†ã®URLã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    unprocessed_urls = [url for url in target_edit_urls if url not in processed_urls]
    
    if not unprocessed_urls:
        print(f"âœ… ã™ã¹ã¦å‡¦ç†æ¸ˆã¿ã§ã™ï¼ˆæ—¢å‡¦ç†: {len(target_edit_urls)} ä»¶ï¼‰")
        return
    
    print(f"\nğŸ“‹ æœªå‡¦ç†: {len(unprocessed_urls)} ä»¶")
    print(f"ğŸ“‹ æ—¢å‡¦ç†: {len(target_edit_urls) - len(unprocessed_urls)} ä»¶")
    
    # å‰Šé™¤
    delete_products(unprocessed_urls)

if __name__ == '__main__':
    main()
